predictRisk(
object = multiple.fit[[i]],
cause = primary.event,
newdata = new.patient,
times = time.horizon
)
}
prediction_matrix <- sapply(1:length(multiple.fit), ff)
if(dim(new.patient)[1] == 1){
prediction <- mean(prediction_matrix)
} else{
prediction <- apply(prediction_matrix, 1, mean)
}
} else if(!is.null(single.fit)){
prediction <-
predictRisk(
object = single.fit,
cause = primary.event,
newdata = new.patient,
times = time.horizon
)
}
return(prediction)
}
time.horizon <- 5
primary.event <- 1
new.patient <- data.frame(x1 = 1, x2 = -1.2, x3 = as.factor(1), x4 = as.factor(0))
prediction.competing(new.patient, multiple.fit = fit.model, time.horizon = time.horizon, primary.event = primary.event)
complete.data <- survdat[complete.cases(survdat[,1:5]),]
predicted.competing <- prediction.competing(complete.data, multiple.fit = fit.model, time.horizon = time.horizon, primary.event = primary.event)
# calibration in the large
# First calculate Aalen-Johansen estimate (as 'observed')
library(survival)
complete.data$event <- factor(complete.data$status, 0:2, labels=c("censor", "event", "competing"))
obj <- summary(survfit(Surv(time, event) ~ 1, data = complete.data), times = time.horizon)
aj <- list("obs" = obj$pstate[, primary.event + 1], "se" = obj$std.err[, primary.event + 1])
# Calculate O/E
OE <- aj$obs / mean(predicted.competing)
# For the confidence interval we use method proposed in Debray et al. (2017) doi:10.1136/bmj.i6460
OE_summary <- c(
"OE" = OE,
"lower" = exp(log(OE - qnorm(0.975) * aj$se / aj$obs)),
"upper" = exp(log(OE + qnorm(0.975) * aj$se / aj$obs))
)
OE_summary
# drawing calibration plots
score_vdata <- Score(
list("csh_validation" = fit.model[[1]]),
formula = Hist(time, status) ~ 1,
cens.model = "km",
data = imputed[[1]],
conf.int = TRUE,
times = time.horizon,
metrics = c("auc", "brier"),
summary = c("ipa"),
cause = primary.event,
plots = "calibration"
)
calplot_pseudo <- plotCalibration(
x = score_vdata,
brier.in.legend = FALSE,
auc.in.legend = FALSE,
cens.method = "pseudo",
bandwidth = 0.05, # leave as NULL for default choice of smoothing
cex = 1,
round = FALSE, # Important, keeps all unique risk estimates rather than rounding
xlim = c(0, 0.6),
ylim = c(0, 0.6),
rug = TRUE,
xlab = "Estimated risks",
ylab = "Observed outcome proportions"
)
# Assess apparent performance (no optimism correction) -------------------
library(geepack) #geese
library(pec) #c-index
calculate_performance <- function(fit.model = NULL, time = NULL,
status = NULL, data.used = NULL,
time.horizon = NULL, primary.event = NULL){
score_vdata <- Score(
list("csh_validation" = fit.model),
formula = Hist(time, status) ~ 1,
cens.model = "km",
data = data.used,
conf.int = TRUE,
times = time.horizon,
metrics = c("auc", "brier"),
summary = c("ipa"),
cause = primary.event,
plots = "calibration"
)
# Use pseudo-observations calculated by Score() (can alternatively use pseudo::pseudoci)
pseudos <- data.frame(score_vdata$Calibration$plotframe)
pseudos <- pseudos[order(pseudos$risk), ]
# Note:
# - 'pseudos' is the data.frame with ACTUAL pseudo-observations, not the smoothed ones
# - Column ID is not the id in vdata; it is just a number assigned to each row of
# the original validation data sorted by time and event indicator
# head(pseudos$pseudovalue) # the pseudo-observations
# Add the cloglog risk estimates to dataset with pseudo-observations
pseudos$cll_pred <- log(-log(1 - pseudos$risk))
# Fit model for calibration intercept
fit_cal_int <- geese(
pseudovalue ~ offset(cll_pred),
data = pseudos,
id = ID,
scale.fix = TRUE,
family = gaussian,
mean.link = "cloglog",
corstr = "independence",
jack = TRUE
)
# Fit model for calibration slope
fit_cal_slope <- geese(
pseudovalue ~ offset(cll_pred) + cll_pred,
data = pseudos,
id = ID,
scale.fix = TRUE,
family = gaussian,
mean.link = "cloglog",
corstr = "independence",
jack = TRUE
)
# AUC as described in paper - same as AUC_2 from timeROC::timeROC()
AUC <- score_vdata$AUC$score$AUC
cindex_csh <- cindex(
object = fit.model,
formula = Hist(time, status) ~ 1,
cause = primary.event,
eval.times = time.horizon,
data = data.used
)$AppCindex$CauseSpecificCox
returnVec <- c("calibration intercept" = summary(fit_cal_int)$mean$estimate,
"calibration slope" = 1 + summary(fit_cal_slope)$mean["cll_pred",]$estimate,
"AUC" = AUC,
"c-index" = cindex_csh)
return(returnVec)
}
apparent.competing.list <- matrix(NA, nrow = n.impute, ncol = 4)
for(i in 1:n.impute){
apparent.competing.list[i,]<- calculate_performance(fit.model = fit.model[[i]],
time = complete.data$time,
status = complete.data$status,
data.used = complete.data,
time.horizon = time.horizon,
primary.event = primary.event)
}
apparent.competing <- apply(apparent.competing.list, 2, mean)
apparent.competing.list
apparent.competing
remove(list=ls())
set.seed(42) # the answer to life the universe and everything
#CHECK
#https://www.rdocumentation.org/packages/rstpm2/versions/1.2.2/topics/pstpm2
# sample size calculations ------------------------------------------------
library(pmsampsize)
pmsampsize(type = "s", rsquared = 0.10, parameters = 10, rate = 0.1,
timepoint = 2, meanfup = 5)
# simulate data
library(MASS)
N <- 10000
Sigma <- outer(1:10, 1:10, function(x,y) 0.5^abs(x-y)) #variance covariance matrix for covariates
x <- mvrnorm(n = N, rep(0, 10), Sigma)
x[,3] <- ifelse(x[,3] > 0.5, 1, 0) #binary predictor
x[,4] <- ifelse(x[,4] > 0, 1, 0) #binary predictor
x[,5] <- ifelse(x[,5] > 1, 1, 0) #binary predictor
x[,8] <- ifelse(x[,8] > 2, 1, 0) #binary auxiliary variable
x[,9] <- ifelse(x[,9] > 2, 1, 0) #binary auxiliary variable
x[,10] <- cut(x[,10], breaks=c(-Inf, -1, 1, 2, Inf)) #categorical with 4 categories
survdat.compl <- data.frame(x)
colnames(survdat.compl) <- paste0("x", 1:10)
rate <- with(survdat.compl, exp(x1+0.4*x1^2+0.4*x2+0.05*x2^2+(x3==2)+0.5*(x4==2)-
0.5*(x5==1)+rnorm(N,0,0.1))/10)
survdat.compl[,c(3:5, 8:10)] <- lapply(survdat.compl[,c(3:5, 8:10)], factor)
fulltime <- rexp(N, rate = rate)
censtimes <- 10 + 20*runif(N)
mean(censtimes)
survdat.compl$time <- pmin(fulltime, censtimes)
survdat.compl$status <- as.numeric(censtimes > fulltime)
table(survdat.compl$status)
# produce missing values
library(devtools)
source_url('https://raw.githubusercontent.com/R-miss-tastic/website/master/static/how-to/generate/amputation.R')
survdat <- survdat.compl
survdat[,1:10] <- produce_NA(survdat.compl[,1:10], mechanism="MAR", perc.missing = 0.1)$data.incomp
# create clusters
survdat$clust <- factor(sample(1:5, size = N, replace = TRUE, prob = rep(0.2,5)))
survdat <- survdat[order(survdat$clust),]
head(survdat)
# KM curves
library(ggplot2)
library(ggfortify)
library(survival)
model_fit <- survfit(Surv(time, status) ~ 1, data=survdat)
autoplot(model_fit) +
labs(x = "\n Survival Time (Days) ", y = "Survival Probabilities \n",
title = "Survival Times") +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", size = 12),
axis.title.y = element_text(face="bold", size = 12),
legend.title = element_text(face="bold", size = 10))
### plot survival curves for specific levels of covariates
model_fit2 <- survfit(Surv(time, status) ~ x5, data=survdat)
autoplot(model_fit2) +
labs(x = "\n Survival Time (Days) ", y = "Survival Probabilities \n",
title = "Survival Times") +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", size = 12),
axis.title.y = element_text(face="bold", size = 12),
legend.title = element_text(face="bold", size = 10)) + xlim(0,30)
# Imputing missing data
library(mice)
n.impute <- 10
# https://www.ebpi.uzh.ch/dam/jcr:dc0cef17-29c7-4e61-8d33-e690561ab7ae/mi_intro20191001.pdf
survdat$nelsonaalen <- nelsonaalen(survdat, time, status)
meth <- make.method(survdat)
pred <- make.predictorMatrix(survdat)
pred[,"time"] <- 0 # don't include time variable in the imputation;instead we have baseline hazard
imp.surv <- mice(survdat, m = n.impute)
imputed <- list()
impc <- complete(imp.surv, action="long")
for(i in 1:n.impute){
imputed[[i]] <- impc[impc$.imp==i, c(3:7, 13:15)]
}
# Weibull model with smoothing splines
fit.model <- list()
for(i in 1:n.impute){
fit.model[[i]] <- survreg(Surv(time, status)~pspline(x1, df=2)+pspline(x2, df=2)+ridge(x3,x4, scale=T),
imputed[[i]], dist="weibul")
}
# predict linear predictor for new patient
prediction.weibull <- function(new.patient, single.fit = NULL, multiple.fit = NULL){
if(!is.null(multiple.fit)){
ff <- function(i){
predict(multiple.fit[[i]], newdata = new.patient, type = "lp")
}
prediction_matrix <- sapply(1:length(multiple.fit), ff)
if(dim(new.patient)[1] == 1){
prediction <- mean(prediction_matrix)
} else{
prediction <- apply(prediction_matrix, 1, mean)
}
} else if(!is.null(single.fit)){
prediction <- predict(single.fit, newdata = new.patient, type = "lp")
}
return(prediction)
}
new.patient <- data.frame(x1 = 1, x2 = -1.2, x3 = as.factor(1), x4 = as.factor(2))
prediction.weibull(new.patient, multiple.fit = fit.model)
complete.data <- survdat[complete.cases(survdat[,1:5]),]
predicted.weibull <- prediction.weibull(complete.data, multiple.fit = fit.model)
# Assess apparent performance (no optimism correction) -------------------
calculate_performance <- function(time = NULL, status = NULL, lp = NULL){
#discrimination
harrell_C <- concordance(Surv(time, status) ~ lp)
harrell_C_est <- harrell_C$concordance
#harrell_C_var <- harrell_C$var
Uno_C <- concordance(Surv(time, status) ~ lp, timewt = "n/G2")
Uno_C_est <- Uno_C$concordance
#Uno_C_var <- Uno_C$var
#calibration
second_model <- survreg(Surv(time, status) ~ lp, dist="weibul")
calslope <- second_model$coef[2]
returnVec <- c(harrell_C_est, Uno_C_est, calslope)
names(returnVec) <- c("Harrel_C", "Uno_C", "calslope")
return(returnVec)
}
apparent.weibull <- calculate_performance(time = complete.data$time, status = complete.data$status,
lp = predicted.weibull)
apparent.weibull
remove(list=ls())
set.seed(42) # the answer to life the universe and everything
#CHECK
#https://www.rdocumentation.org/packages/rstpm2/versions/1.2.2/topics/pstpm2
# sample size calculations ------------------------------------------------
library(pmsampsize)
pmsampsize(type = "s", rsquared = 0.10, parameters = 10, rate = 0.1,
timepoint = 2, meanfup = 5)
# simulate data
library(MASS)
N <- 50000
Sigma <- outer(1:10, 1:10, function(x,y) 0.5^abs(x-y)) #variance covariance matrix for covariates
x <- mvrnorm(n = N, rep(0, 10), Sigma)
x[,3] <- ifelse(x[,3] > 0.5, 1, 0) #binary predictor
x[,4] <- ifelse(x[,4] > 0, 1, 0) #binary predictor
x[,5] <- ifelse(x[,5] > 1, 1, 0) #binary predictor
x[,8] <- ifelse(x[,8] > 2, 1, 0) #binary auxiliary variable
x[,9] <- ifelse(x[,9] > 2, 1, 0) #binary auxiliary variable
x[,10] <- cut(x[,10], breaks=c(-Inf, -1, 1, 2, Inf)) #categorical with 4 categories
survdat.compl <- data.frame(x)
colnames(survdat.compl) <- paste0("x", 1:10)
rate <- with(survdat.compl, exp(x1+0.4*x1^2+0.4*x2+0.05*x2^2+(x3==2)+0.5*(x4==2)-
0.5*(x5==1)+rnorm(N,0,0.1))/10)
survdat.compl[,c(3:5, 8:10)] <- lapply(survdat.compl[,c(3:5, 8:10)], factor)
fulltime <- rexp(N, rate = rate)
censtimes <- 10 + 20*runif(N)
mean(censtimes)
survdat.compl$time <- pmin(fulltime, censtimes)
survdat.compl$status <- as.numeric(censtimes > fulltime)
table(survdat.compl$status)
# produce missing values
library(devtools)
source_url('https://raw.githubusercontent.com/R-miss-tastic/website/master/static/how-to/generate/amputation.R')
survdat <- survdat.compl
survdat[,1:10] <- produce_NA(survdat.compl[,1:10], mechanism="MAR", perc.missing = 0.1)$data.incomp
# create clusters
survdat$clust <- factor(sample(1:5, size = N, replace = TRUE, prob = rep(0.2,5)))
survdat <- survdat[order(survdat$clust),]
head(survdat)
# KM curves
library(ggplot2)
library(ggfortify)
library(survival)
model_fit <- survfit(Surv(time, status) ~ 1, data=survdat)
autoplot(model_fit) +
labs(x = "\n Survival Time (Days) ", y = "Survival Probabilities \n",
title = "Survival Times") +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", size = 12),
axis.title.y = element_text(face="bold", size = 12),
legend.title = element_text(face="bold", size = 10))
### plot survival curves for specific levels of covariates
model_fit2 <- survfit(Surv(time, status) ~ x5, data=survdat)
autoplot(model_fit2) +
labs(x = "\n Survival Time (Days) ", y = "Survival Probabilities \n",
title = "Survival Times") +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", size = 12),
axis.title.y = element_text(face="bold", size = 12),
legend.title = element_text(face="bold", size = 10)) + xlim(0,30)
# Imputing missing data
library(mice)
n.impute <- 10
# https://www.ebpi.uzh.ch/dam/jcr:dc0cef17-29c7-4e61-8d33-e690561ab7ae/mi_intro20191001.pdf
survdat$nelsonaalen <- nelsonaalen(survdat, time, status)
meth <- make.method(survdat)
pred <- make.predictorMatrix(survdat)
pred[,"time"] <- 0 # don't include time variable in the imputation;instead we have baseline hazard
imp.surv <- mice(survdat, m = n.impute)
imputed <- list()
impc <- complete(imp.surv, action="long")
for(i in 1:n.impute){
imputed[[i]] <- impc[impc$.imp==i, c(3:7, 13:15)]
}
# Weibull model with smoothing splines
fit.model <- list()
for(i in 1:n.impute){
fit.model[[i]] <- survreg(Surv(time, status)~pspline(x1, df=2)+pspline(x2, df=2)+ridge(x3,x4, scale=T),
imputed[[i]], dist="weibul")
}
# predict linear predictor for new patient
prediction.weibull <- function(new.patient, single.fit = NULL, multiple.fit = NULL){
if(!is.null(multiple.fit)){
ff <- function(i){
predict(multiple.fit[[i]], newdata = new.patient, type = "lp")
}
prediction_matrix <- sapply(1:length(multiple.fit), ff)
if(dim(new.patient)[1] == 1){
prediction <- mean(prediction_matrix)
} else{
prediction <- apply(prediction_matrix, 1, mean)
}
} else if(!is.null(single.fit)){
prediction <- predict(single.fit, newdata = new.patient, type = "lp")
}
return(prediction)
}
new.patient <- data.frame(x1 = 1, x2 = -1.2, x3 = as.factor(1), x4 = as.factor(2))
prediction.weibull(new.patient, multiple.fit = fit.model)
complete.data <- survdat[complete.cases(survdat[,1:5]),]
predicted.weibull <- prediction.weibull(complete.data, multiple.fit = fit.model)
# Assess apparent performance (no optimism correction) -------------------
calculate_performance <- function(time = NULL, status = NULL, lp = NULL){
#discrimination
harrell_C <- concordance(Surv(time, status) ~ lp)
harrell_C_est <- harrell_C$concordance
#harrell_C_var <- harrell_C$var
Uno_C <- concordance(Surv(time, status) ~ lp, timewt = "n/G2")
Uno_C_est <- Uno_C$concordance
#Uno_C_var <- Uno_C$var
#calibration
second_model <- survreg(Surv(time, status) ~ lp, dist="weibul")
calslope <- second_model$coef[2]
returnVec <- c(harrell_C_est, Uno_C_est, calslope)
names(returnVec) <- c("Harrel_C", "Uno_C", "calslope")
return(returnVec)
}
apparent.weibull <- calculate_performance(time = complete.data$time, status = complete.data$status,
lp = predicted.weibull)
exp(0.09)
exp(-0.09)
exp(-0.03)
exp(-0.03 - 1.96 * 0.14)
exp(−0.09 − 0.00 × 80 − 0.03 − 0.08 − 0.16 − 0.06 − 0.04 × 5)
exp(-0.09 - 0.00 * 80 - 0.03 - 0.08 - 0.16 - 0.06 - 0.04 * 5)
# We changed name of the methods
# naive method -> restrict predictor method
# separate prediction method -> ensemble method
#devtools::install_github("MikeJSeo/bipd")
library(bipd)
library(dplyr)
library(mvtnorm)
library(lme4)
library(micemd)
setwd("C:/Users/swj88/Documents/Github/phd/missing")
source("helpful.functions.R")
source("simulation.functions.R")
####################################
# type of variable
type_of_var <- c("continuous", "binary", "binary", "continuous", "continuous", "continuous", "continuous", "binary", "binary", "binary")
names(type_of_var) <- paste0("x", 1:10)
setwd("C:/Users/swj88/Documents/Github/phd/missing/simulation_results")
options(warn=-1) #options(warn=0)
load("simulation20.RData")
wrapper_function2(result)
load("simulation21.RData")
wrapper_function2(result)
load("simulation22.RData")
wrapper_function2(result)
load("simulation23.RData")
wrapper_function2(result)
load("simulation24.RData")
wrapper_function2(result)
load("simulation25.RData")
wrapper_function2(result)
load("simulation26.RData")
wrapper_function2(result)
load("simulation27.RData")
wrapper_function2(result)
load("simulation28.RData")
wrapper_function2(result)
load("simulation29.RData")
wrapper_function2(result)
load("simulation30.RData")
wrapper_function2(result)
load("simulation31.RData")
wrapper_function2(result)
load("simulation31.RData")
wrapper_function2(result)
load("simulation32.RData")
wrapper_function2(result)
load("simulation33.RData")
wrapper_function2(result)
load("simulation28.RData")
wrapper_function2(result)
load("simulation33.RData")
wrapper_function2(result)
load("simulation34.RData")
wrapper_function2(result)
load("simulation35.RData")
wrapper_function2(result)
load("simulation36.RData")
wrapper_function2(result)
load("simulation37.RData")
wrapper_function2(result)
load("simulation38.RData")
wrapper_function2(result)
load("simulation39.RData")
wrapper_function2(result)
load("simulation40.RData")
wrapper_function2(result)
load("simulation41.RData")
wrapper_function2(result)
load("simulation42.RData")
wrapper_function2(result)
load("simulation43.RData")
wrapper_function2(result)
load("simulation44.RData")
wrapper_function2(result)
load("simulation45.RData")
wrapper_function2(result)
load("simulation46.RData")
wrapper_function2(result)
load("simulation47.RData")
wrapper_function2(result)
load("simulation48.RData")
wrapper_function2(result)
load("simulation49.RData")
wrapper_function2(result)
load("simulation49.RData")
wrapper_function2(result)
load("simulation50.RData")
wrapper_function2(result)
load("simulation51.RData")
wrapper_function2(result)
load("simulation52.RData")
wrapper_function2(result)
load("simulation53.RData")
wrapper_function2(result)
load("simulation54.RData")
wrapper_function2(result)
load("simulation55.RData")
wrapper_function2(result)
load("simulation56.RData")
wrapper_function2(result)
load("simulation57.RData")
wrapper_function2(result)
load("simulation58.RData")
wrapper_function2(result)
load("simulation59.RData")
wrapper_function2(result)
load("simulation60.RData")
wrapper_function2(result)
load("simulation60.RData")
wrapper_function2(result)
load("simulation61.RData")
wrapper_function2(result)
load("simulation62.RData")
wrapper_function2(result)
load("simulation63.RData")
wrapper_function2(result)
load("simulation64.RData")
wrapper_function2(result)
